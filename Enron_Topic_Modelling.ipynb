{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os,codecs,sys,re,json\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "my_stop=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Enron_data/Enron_clean_email_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Here is our forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can you send me a schedule of the salary and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              email\n",
       "0           0                               Here is our forecast\n",
       "1           1  Traveling to have a business meeting takes the...\n",
       "2           2                     test successful.  way to go!!!\n",
       "3           3   Can you send me a schedule of the salary and ...\n",
       "4           4                Let's shoot for Tuesday at 11:45.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [w for w in tokens if not w in my_stop]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(documents[doc_index])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = data.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_email = data['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_email=[preprocess(sent)  for sent in data_email]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.65, min_df=5, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_email)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_df is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\". For example:\n",
    "\n",
    "- max_df = 0.50 means \"ignore terms that appear in more than 50% of the documents\".\n",
    "- max_df = 25 means \"ignore terms that appear in more than 25 documents\".\n",
    "- The default max_df is 1.0, which means \"ignore terms that appear in more than 100% of the documents\". Thus, the default setting does not ignore any terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_df is used for removing terms that appear too infrequently. For example:\n",
    "\n",
    "- min_df = 0.01 means \"ignore terms that appear in less than 1% of the documents\".\n",
    "- min_df = 5 means \"ignore terms that appear in less than 5 documents\".\n",
    "- The default min_df is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "nmf_W = nmf_model.transform(tfidf)\n",
    "nmf_H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "project need let know week\n",
      "please respond cbpres austin rr com enclosed preliminary proforma westgate property austinthat told tell proforma projectshould produce truly exceptional return 40 per year 3 years especially attractive project market strong ashave uncovered date austin market smart growth corridor area designated city austinfor preferred development fast tracked completewater treatment ordinances waived estimated lotimprovement costs based 28 lot development investigated northwidening even though property likely require streetwidening less detention retention filtration pondrequirement used data cautious expected impact sales significantly projects quiteis uneven included fence around entire property mayonly put westgate cameron loop gated communities farpreferred good idea screening current buyeran extended escrow enable us probably obtain approved siteplan closing contract mean close intoprofits project discussed san marcos also discusshaving invest lots sell lots construction entitywith profit lot believe would facilitate use abe equity project would need discuss anantonio know anyone send package property prepared broker read package reviewed proforma would want toschedule tour site area please get back soon asyour schedule permits regarding site visit feel free call anytime reach weekend evening either512 338 1119 512 338 1110 cell phone 512 748 7495 fax is512 338 1103 look forward hearing working youon project sure major winner regret took long get back unusualdowndrafts hit south part austin building 10 town homes one units roof decked siding scheduled tostart next day severe downdraft hitting decked roof enoughto knock city shut project week tookanother week get every thing back tract last week takein spine causes extreme pain kept bedridden thispast week nothing like wife incapacitated realizethe enormous number things everyday fortunately looks asif ok long run\n",
      "please respond cbpres austin rr com enclosed preliminary proforma westgate property austinthat told tell proforma projectshould produce truly exceptional return 40 per year 3 years especially attractive project market strong ashave uncovered date austin market smart growth corridor area designated city austinfor preferred development fast tracked completewater treatment ordinances waived estimated lotimprovement costs based 28 lot development investigated northwidening even though property likely require streetwidening less detention retention filtration pondrequirement used data cautious expected impact sales significantly projects quiteis uneven included fence around entire property mayonly put westgate cameron loop gated communities farpreferred good idea screening current buyeran extended escrow enable us probably obtain approved siteplan closing contract mean close intoprofits project discussed san marcos also discusshaving invest lots sell lots construction entitywith profit lot believe would facilitate use abe equity project would need discuss anantonio know anyone send package property prepared broker read package reviewed proforma would want toschedule tour site area please get back soon asyour schedule permits regarding site visit feel free call anytime reach weekend evening either512 338 1119 512 338 1110 cell phone 512 748 7495 fax is512 338 1103 look forward hearing working youon project sure major winner regret took long get back unusualdowndrafts hit south part austin building 10 town homes one units roof decked siding scheduled tostart next day severe downdraft hitting decked roof enoughto knock city shut project week tookanother week get every thing back tract last week takein spine causes extreme pain kept bedridden thispast week nothing like wife incapacitated realizethe enormous number things everyday fortunately looks asif ok long run\n",
      "Topic 1:\n",
      "meeting 00 starting 2000 weekend\n",
      "sent cindy cicchettistart 09 28 2000 01 00 pmthis meeting repeats starting date occurs weekend meeting meeting richard burchfield hou ect rescheduled\n",
      "sent cindy cicchettistart 10 03 2000 02 30 pmthis meeting repeats starting date occurs weekend meeting sent cindy cicchettistart 10 03 2000 02 30 pmthis meeting repeats starting date occurs weekend meeting allan severude acceptedscott mills acceptedsent cindy cicchettistart 09 27 2000 02 00 pmthis meeting repeats starting date occurs weekend meeting sent cindy cicchettistart 09 27 2000 02 00 pmthis meeting repeats starting date occurs weekend meeting allan severude acceptedjeffrey c gossett acceptedjayant krishnaswamy acceptedrussell long acceptedsent cindy cicchettistart 09 28 2000 01 00 pmthis meeting repeats starting date occurs weekend meeting sent cindy cicchettistart 09 28 2000 01 00 pmthis meeting repeats starting date occurs weekend meeting allan severude acceptedscott mills acceptedruss severson acceptedthis meeting moved 4 00 wed room 2601 sent\n",
      "Topic 2:\n",
      "trades socal september vs spreadsheet\n",
      "spreadsheet detailing september socal trades distinguish buys vs sells\n",
      "spreadsheet detailing september socal trades distinguish buys vs sells\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 5\n",
    "no_top_documents = 2\n",
    "display_topics(nmf_H, nmf_W, tfidf_feature_names, data_email, no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LDA for topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nirale1.kumar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics_lda(model, feature_names, no_top_words):\n",
    "    results={}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topicId='Topic '+str(topic_idx)\n",
    "        topicName=\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "        results[topicId]=topicName\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Topic 0': 'email want think information gas',\n",
       " 'Topic 1': 'let receive need know units',\n",
       " 'Topic 2': 'meeting spreadsheet socal date address'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_topics_lda(lda, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
